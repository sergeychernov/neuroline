---
description: Правила для core пакета neuroline
globs: packages/neuroline/**/*
---

# Пакет: neuroline (Core)

## Назначение

Ядро библиотеки — PipelineManager, Storage абстракции, типы. Фреймворк-агностик, без внешних зависимостей.

## Принципы

- **Без внешних runtime зависимостей** (только Node.js built-ins)
- Все peer dependencies — **optional** (mongoose, react, mui)
- Dual exports: `neuroline` и `neuroline/mongo`
- Storage — абстракция через интерфейс `PipelineStorage`

## Структура

```
src/
├── index.ts           # Публичные экспорты
├── types.ts           # Все типы и интерфейсы
├── manager.ts         # PipelineManager класс
├── storage.ts         # InMemoryPipelineStorage + интерфейс
├── mongo-storage.ts   # MongoPipelineStorage
├── mongoose-schema.ts # Mongoose схема
└── mongo.ts           # Экспорты для neuroline/mongo
```

## Ключевые сущности

### JobDefinition

Чистая функция с типизированным интерфейсом:

```typescript
export const myJob: JobDefinition<Input, Output, Options> = {
    name: 'my-job',
    async execute(input, options, ctx) {
        ctx.logger.info('Processing', { input });
        return { result: 'done' };
    },
};
```

### synapses

Функция `(ctx: SynapseContext) => TInput` для подготовки входных данных job:

```typescript
{
    job: processJob,
    synapses: (ctx) => ({
        data: ctx.getArtifact<FetchResult>('fetch-data')?.data,
        userId: ctx.pipelineInput.userId,
    }),
}
```

### PipelineConfig

```typescript
const config: PipelineConfig<MyInput> = {
    name: 'my-pipeline',
    stages: [
        jobA,                    // Stage 1: одна job
        [jobB, jobC],            // Stage 2: параллельно
        { job: jobD, synapses }, // Stage 3: с трансформацией
        { job: unstableJob, synapses, retries: 2, retryDelay: 1500 }, // Stage 4: с retry
    ],
    computeInputHash: (input) => `${input.userId}`, // Опционально
};
```

### Retry

Job может быть настроена на автоматический retry при ошибке:

```typescript
{
    job: unstableJob,
    synapses: (ctx) => ({ ... }),
    retries: 2,        // Максимум 3 попытки (1 + 2 ретрая)
    retryDelay: 1500,  // Задержка 1.5с между попытками
}
```

- `retryCount` и `maxRetries` сохраняются в `JobState` для мониторинга

### PipelineStorage

Интерфейс для хранилища. Реализации:
- `InMemoryPipelineStorage` — для тестов
- `MongoPipelineStorage` — для продакшена

### Stale Jobs Watchdog

Фоновый мониторинг "зависших" джоб (застрявших в `processing` из-за падения процесса):

```typescript
// Запуск watchdog
manager.startStaleJobsWatchdog({
    checkIntervalMs: 60_000,     // проверка раз в минуту
    jobTimeoutMs: 20 * 60_000,   // таймаут 20 минут
});

// Остановка
manager.stopStaleJobsWatchdog();

// Ручная проверка (для тестов)
await manager.timeoutStaleJobs();
```

- Метод `findAndTimeoutStaleJobs()` в `PipelineStorage` — находит и таймаутит зависшие джобы
- Watchdog использует `setInterval` с `unref()` — не блокирует завершение процесса

### Restart Pipeline

Перезапуск pipeline с указанной job (для исправления ошибок или повторного выполнения):

```typescript
// Перезапуск с job "transform" с новыми опциями
const result = await manager.restartPipelineFromJob(pipelineId, 'transform', {
    jobOptions: { transform: { format: 'csv' } },
    onExecutionStart: (promise) => waitUntil(promise),
});

console.log(result.fromJobName);   // 'transform'
console.log(result.jobsToRerun);   // количество jobs для перезапуска
```

- Перезапускается только указанная job и все последующие stages
- Другие jobs того же stage (если они `done`) сохраняют артефакты и не перезапускаются
- Артефакты сохранённых jobs доступны через `synapses`
- Retry счётчик и errors сбрасываются для перезапускаемых jobs
- Новые `jobOptions` полностью заменяют существующие
- Pipeline не может быть перезапущен если он в статусе `processing`

**Client API:**

```typescript
// Перезапуск с polling
const polling = await client.restartAndPoll(
    pipelineId,
    'jobName',
    { jobOptions },
    onUpdate,
    onError,
);
```

## Правила

1. **Job должна быть чистой функцией** — не обращаться к глобальному состоянию
2. **Артефакты immutable** — не мутировать результаты других jobs
3. **Типизация обязательна** — `JobDefinition<TInput, TOutput, TOptions>`
4. **Имена jobs уникальны** в рамках pipeline
5. **synapses** — единственный способ получить данные из других jobs

## Идемпотентность

Pipeline ID = hash(pipelineType + input). Повторный запуск с теми же данными возвращает существующий pipeline.

## Инвалидация

При изменении структуры pipeline (добавление/удаление/переименование jobs) старые записи автоматически инвалидируются по `configHash`.
